# yaml-language-server: $schema=./values.schema.json
default:
  # List of environment variables applied to all components
  env:
    - name: OTEL_SERVICE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: "metadata.labels['app.kubernetes.io/component']"
    - name: OTEL_COLLECTOR_NAME
      value: otel-collector
    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      value: cumulative
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version={{ .Chart.AppVersion }}'
  # Allows overriding and additions to .Values.default.env
  envOverrides: []
  #  - name: OTEL_K8S_NODE_NAME
  #    value: "someConstantValue"
  image:
    repository: ghcr.io/open-telemetry/demo
    # Overrides the image tag whose default is the chart appVersion.
    # The service's name will be applied to the end of this value.
    tag: ""
    pullPolicy: IfNotPresent
    pullSecrets: []
  # Default # of replicas for all components
  replicas: 1
  # default revisionHistoryLimit for all components (number of old ReplicaSets to retain)
  revisionHistoryLimit: 10
  # Default schedulingRules for all components
  schedulingRules:
    nodeSelector: {}
    affinity: {}
    tolerations: []
  # Default securityContext for all components
  securityContext: 
    runAsUser: 1012310000
    runAsNonRoot: true
    runAsGroup: 1012310000
  # Default pod security context for all components
  podSecurityContext:
    runAsUser: 1012310000
    runAsNonRoot: true
    runAsGroup: 1012310000
    fsGroup: 1012310000

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

components:
  ## Demo Components are named objects (services) with several properties
  # demoService:
  ## Enable the component (service)
  #   enabled: true
  #   useDefault:
  ## Use default environment variables
  #     env: true
  ## Override Image repository and Tag. Tag will use appVersion as default.
  ## Component's name will be applied to end of this value.
  #   imageOverride: {}
  ## Optional service definitions to apply
  #   service:
  ## Service Type to use for this component. Default is ClusterIP.
  #     type: ClusterIP
  ## Service Port to use to expose this component. Default is nil
  #     port: 8080
  ## Service Node Port to use to expose this component on a NodePort service. Default is nil
  #     nodePort: 30080
  ## Service Annotations to add to this component
  #     annotations: {}
  ## Additional service ports to use to expose this component
  #   ports:
  #     - name: extraServicePort
  #       value: 8081
  ## Environment variables to add to the component's pod
  #   env:
  ## Environment variables that upsert (append + merge) into the `env` specification for this component.
  ## A variable named OTEL_RESOURCE_ATTRIBUTES_EXTRA will have its value appended to the OTEL_RESOURCE_ATTRIBUTES value.
  #   envOverrides:
  ## Pod Scheduling rules for nodeSelector, affinity, or tolerations.
  #   schedulingRules:
  #     nodeSelector: {}
  #     affinity: {}
  #     tolerations: []
  ## Pod Annotations to add to this component
  #   podAnnotations: {}
  ## Resources for this component
  #   resources: {}
  ## Container security context for setting user ID (UID), group ID (GID) and other security policies
  #   securityContext:
  ## Ingresses rules to add for the to the component
  # ingress:
  ## Enable the creation of Ingress rules. Default is false
  #   enabled: false
  ## Annotations to add to the ingress rule
  #   annotations: {}
  ## Which Ingress class (controller) to use. Default is unspecified.
  #   ingressClassName: nginx
  ## Hosts definitions for the Ingress rule
  #   hosts:
  #     - host: demo.example.com
  ## Each host can have multiple paths/routes
  #       paths:
  #         - path: /
  #           pathType: Prefix
  #           port: 8080
  ## Optional TLS specifications for the Ingress rule
  #   tls:
  #     - secretName: demo-tls
  #       hosts:
  #         - demo.example.com
  ## Additional ingresses - only created if ingress.enabled is true
  ## Useful for when differently annotated ingress services are required
  ## Each additional ingress needs key "name" set to something unique
  #   additionalIngresses: []
  #     - name: extra-demo-ingress
  #       ingressClassName: nginx
  #       annotations: {}
  #       hosts:
  #         - host: demo.example.com
  #           paths:
  #             - path: /
  #               pathType: Prefix
  #               port: 8080
  #       tls:
  #         - secretName: demo-tls
  #           hosts:
  #             - demo.example.com
  ## Command to use in the container spec, in case you don't want to go with the default command from the image.
  #   command: []
  ## Configuration to for this component; will create a Volume, and Mount backed by an optionally created ConfigMap.
  ## The name, mountPath are required, and one of existingConfigMap or data is required.
  ## If an existing ConfigMap is not provided, the contents under data will be used for the created ConfigMap.
  #   mountedConfigMaps: []
  #     - name: my-config
  #       mountPath: /etc/config
  #       subPath:
  #       existingConfigMap: my-configmap
  #       data:
  #         my-config.yaml: |
  #           key: value
  ## Configuration to create an custom Volume
  #   additionalVolumes:
  #     - name: nginx-logs
  #       hostPath:
  #         path: /var/log/nginx
  #       type: ""
  ## Configuration to mount the custom Volume to the container
  # additionalVolumeMounts:
  #     - name: nginx-logs
  #       mountPath: /var/log/nginx
  # # Kubernetes container health check options
  #   livenessProbe: {}
  # # Optional init container to run before the pod starts.
  #   initContainers:
  #     - name: <init-container-name>
  #       image: <init-container-image>
  #       command: [list of commands for the init container to run]
  # # Replicas for the component
  #  replicas: 1
  # # Number of old ReplicaSets to retain
  #  revisionHistoryLimit: 10
  # # Optional pod security context for setting user ID (UID), group ID (GID) and other security policies
  # # This will be applied at pod level, can be applied globally for all pods: .Values.default.podSecurityContext
  # # Or it can be applied to a specific component: .Values.components.<component-name>.podSecurityContext
  #    podSecurityContext:
  #      runAsGroup: 1012310000
  #      runAsNonRoot: true
  #      runAsUser: 1012310000

  accounting:
    enabled: false
    useDefault:
      env: true
    env:
      - name: KAFKA_ADDR
        value: kafka:9092
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
    resources:
      limits:
        memory: 120Mi
    securityContext:
      runAsUser: 1012310000
      runAsGroup: 1012310000
      runAsNonRoot: true
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command: ["sh", "-c", "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;"]

  ad:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: AD_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
      - name: OTEL_LOGS_EXPORTER
        value: otlp
    resources:
      limits:
        memory: 300Mi

  cart:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CART_PORT
        value: "8080"
      - name: ASPNETCORE_URLS
        value: http://*:$(CART_PORT)
      - name: VALKEY_ADDR
        value: valkey-cart:6379
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 160Mi
    initContainers:
      - name: wait-for-valkey-cart
        image: busybox:latest
        command: ["sh", "-c", "until nc -z -v -w30 valkey-cart 6379; do echo waiting for valkey-cart; sleep 2; done;"]

  checkout:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CHECKOUT_PORT
        value: "8080"
      - name: CART_ADDR
        value: cart:8080
      - name: CURRENCY_ADDR
        value: currency:8080
      - name: EMAIL_ADDR
        value: http://email:8080
      - name: PAYMENT_ADDR
        value: payment:8080
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: SHIPPING_ADDR
        value: shipping:8080
      # Disable Kafka dependency since it's disabled
      # - name: KAFKA_ADDR
      #   value: kafka:9092
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 20Mi
    # Remove init container for Kafka since it's disabled
    # initContainers:
    #   - name: wait-for-kafka
    #     image: busybox:latest
    #     command: ["sh", "-c", "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;"]

  currency:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CURRENCY_PORT
        value: "8080"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
      - name: VERSION
        value: "{{ .Chart.AppVersion }}"
    resources:
      limits:
        memory: 20Mi

  email:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: EMAIL_PORT
        value: "8080"
      - name: APP_ENV
        value: production
      - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
    resources:
      limits:
        memory: 100Mi

  fraud-detection:
    enabled: false
    useDefault:
      env: true
    env:
      - name: KAFKA_ADDR
        value: kafka:9092
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
    resources:
      limits:
        memory: 300Mi
    securityContext:
      runAsUser: 1012310000
      runAsGroup: 1012310000
      runAsNonRoot: true
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command: ["sh", "-c", "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;"]

  frontend:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: FRONTEND_PORT
        value: "8080"
      - name: FRONTEND_ADDR
        value: :8080
      - name: AD_ADDR
        value: ad:8080
      - name: CART_ADDR
        value: cart:8080
      - name: CHECKOUT_ADDR
        value: checkout:8080
      - name: CURRENCY_ADDR
        value: currency:8080
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: RECOMMENDATION_ADDR
        value: recommendation:8080
      - name: SHIPPING_ADDR
        value: shipping:8080
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
      - name: WEB_OTEL_SERVICE_NAME
        value: frontend-web
      - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
        value: https://frontend-proxy-valaise16-dev.apps.rm3.7wse.p1.openshiftapps.com/otlp-http/v1/traces
    resources:
      limits:
        memory: 250Mi
    securityContext:
      runAsUser: 1012310000  # nextjs
      runAsGroup: 1012310000
      runAsNonRoot: true
    ingress:
      enabled: true
      annotations:
        # Let OpenShift create a secure Route
        route.openshift.io/termination: "edge"
        route.openshift.io/insecureEdgeTerminationPolicy: "Redirect"   
      hosts:
        - host: frontend-valaise16-dev.apps.rm3.7wse.p1.openshiftapps.com
          paths:
            - path: /
              pathType: Prefix
              port: 8080
      tls: []

  frontend-proxy:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: ENVOY_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: FLAGD_UI_HOST
        value: flagd
      - name: FLAGD_UI_PORT
        value: "4000"
      - name: FRONTEND_HOST
        value: frontend
      - name: FRONTEND_PORT
        value: "8080"
      - name: GRAFANA_HOST
        value: grafana
      - name: GRAFANA_PORT
        value: "80"
      - name: IMAGE_PROVIDER_HOST
        value: image-provider
      - name: IMAGE_PROVIDER_PORT
        value: "8081"
      - name: TEMPO_HOST
        value: tempo
      - name: TEMPO_PORT
        value: "3200"
      - name: LOCUST_WEB_HOST
        value: load-generator
      - name: LOCUST_WEB_PORT
        value: "8089"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
      - name: OTEL_COLLECTOR_PORT_GRPC
        value: "4317"
      - name: OTEL_COLLECTOR_PORT_HTTP
        value: "4318"
    resources:
      limits:
        memory: 65Mi
    securityContext:
      runAsUser: 1012310000
      runAsGroup: 1012310000
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
      seccompProfile:
        type: RuntimeDefault
    # Add writable volumes for envoy
    additionalVolumes:
      - name: envoy-work
        emptyDir: {}
    additionalVolumeMounts:
      - name: envoy-work
        mountPath: /tmp/envoy
    mountedConfigMaps:
      - name: envoy-config
        mountPath: /home/envoy
        existingConfigMap: otel-demo-envoy-config
    command:
      - "/bin/sh"
      - "-c"
      - "envsubst < /home/envoy/envoy.tmpl.yaml > /tmp/envoy/envoy.yaml && envoy -c /tmp/envoy/envoy.yaml"
    ingress:
      enabled: true
      annotations:
        # Let OpenShift create a secure Route
        route.openshift.io/termination: "edge"
        route.openshift.io/insecureEdgeTerminationPolicy: "Redirect"   
      hosts:
        - host: frontend-proxy-valaise16-dev.apps.rm3.7wse.p1.openshiftapps.com
          paths:
            - path: /
              pathType: Prefix
              port: 8080
      tls: []
      

  image-provider:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8081
    env:
      - name: IMAGE_PROVIDER_PORT
        value: "8081"
      - name: OTEL_COLLECTOR_PORT_GRPC
        value: "4317"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
    resources:
      limits:
        memory: 50Mi
    securityContext:
      runAsUser: 1012310000
      runAsGroup: 1012310000
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
      seccompProfile:
        type: RuntimeDefault
    # Mount writable directory for nginx config
    additionalVolumes:
      - name: nginx-config
        emptyDir: {}
    additionalVolumeMounts:
      - name: nginx-config
        mountPath: /tmp/nginx
    mountedConfigMaps:
      - name: nginx-template
        mountPath: /etc/nginx-templates
        existingConfigMap: otel-demo-nginx-config
    command:
      - "/bin/sh"
      - "-c"
      - "envsubst '$OTEL_COLLECTOR_HOST $IMAGE_PROVIDER_PORT $OTEL_COLLECTOR_PORT_GRPC $OTEL_SERVICE_NAME' < /etc/nginx-templates/nginx.conf.template > /tmp/nginx/nginx.conf && nginx -c /tmp/nginx/nginx.conf -g 'daemon off;'"

  load-generator:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8089
    env:
      - name: LOCUST_WEB_HOST
        value: "0.0.0.0"
      - name: LOCUST_WEB_PORT
        value: "8089"
      - name: LOCUST_USERS
        value: "10"
      - name: LOCUST_SPAWN_RATE
        value: "1"
      - name: LOCUST_HOST
        value: http://frontend-proxy:8080
      - name: LOCUST_HEADLESS
        value: "false"
      - name: LOCUST_AUTOSTART
        value: "true"
      - name: LOCUST_BROWSER_TRAFFIC_ENABLED
        value: "false"
      - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
        value: python
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_OFREP_PORT
        value: "8016"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 1500Mi
    securityContext:
      runAsUser: 1012310000
      runAsGroup: 1012310000
      runAsNonRoot: true

  payment:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: PAYMENT_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 120Mi
    securityContext:
      runAsUser: 1012310000  # node
      runAsGroup: 1012310000
      runAsNonRoot: true

  product-catalog:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: PRODUCT_CATALOG_PORT
        value: "8080"
      - name: PRODUCT_CATALOG_RELOAD_INTERVAL
        value: "10"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    mountedConfigMaps:
      - name: product-catalog-products
        mountPath: /usr/src/app/products
        existingConfigMap: product-catalog-products
    resources:
      limits:
        memory: 20Mi

  quote:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: QUOTE_PORT
        value: "8080"
      - name: OTEL_PHP_AUTOLOAD_ENABLED
        value: "true"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
    resources:
      limits:
        memory: 40Mi
    securityContext:
      runAsUser: 1012310000  # www-data
      runAsGroup: 1012310000
      runAsNonRoot: true

  recommendation:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: RECOMMENDATION_PORT
        value: "8080"
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: OTEL_PYTHON_LOG_CORRELATION
        value: "true"
      - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
        value: python
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 500Mi            # This is high to enable supporting the recommendationCache feature flag use case

  shipping:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: SHIPPING_PORT
        value: "8080"
      - name: QUOTE_ADDR
        value: http://quote:8080
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 20Mi

  flagd:
    enabled: true
    imageOverride:
      repository: "ghcr.io/open-feature/flagd"
      tag: "v0.12.8"
    useDefault:
      env: true
    replicas: 1
    ports:
      - name: rpc
        value: 8013
      - name: ofrep
        value: 8016
    env:
      - name: FLAGD_METRICS_EXPORTER
        value: otel
      - name: FLAGD_OTEL_COLLECTOR_URI
        value: $(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 75Mi
    command:
      - "/flagd-build"
      - "start"
      - "--port"
      - "8013"
      - "--ofrep-port"
      - "8016"
      - "--uri"
      - "file:./etc/flagd/demo.flagd.json"
    mountedEmptyDirs:
      - name: config-rw
        mountPath: /etc/flagd
    # flgad-ui as a sidecar container in the same pod so the flag json file can be shared
    sidecarContainers:
      - name: flagd-ui
        useDefault:
          env: true
        service:
          port: 4000
        env:
          - name: FLAGD_METRICS_EXPORTER
            value: otel
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
        resources:
          limits:
            memory: 100Mi
        volumeMounts:
          - name: config-rw
            mountPath: /app/data
    initContainers:
      - name: init-config
        image: busybox
        command: ["sh", "-c", "cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json"]
        volumeMounts:
          - mountPath: /config-ro
            name: config-ro
          - mountPath: /config-rw
            name: config-rw
    additionalVolumes:
      - name: config-ro
        configMap:
          name: flagd-config

  kafka:
    enabled: false
    useDefault:
      env: false
    replicas: 1
    ports:
      - name: plaintext
        value: 9092
      - name: controller
        value: 9093
    env:
      # Disable Java OTel agent 
      - name: JAVA_TOOL_OPTIONS
        value: ""
      - name: KAFKA_ADVERTISED_LISTENERS
        value: PLAINTEXT://kafka:9092
      - name: KAFKA_HEAP_OPTS
        value: "-Xmx400M -Xms400M"
      # Use writable directories
      - name: KAFKA_LOG_DIRS
        value: "/tmp/kafka-logs"
      - name: KAFKA_METADATA_LOG_DIR
        value: "/tmp/kafka-metadata"
      # Allow Kafka to write configuration
      - name: KAFKA_CONFIG_DIR
        value: "/tmp/kafka-config"
      # Completely disable GC logging for OpenShift
      - name: KAFKA_GC_LOG_OPTS
        value: " "
      - name: KAFKA_JVM_PERFORMANCE_OPTS
        value: " "
    resources:
      limits:
        memory: 600Mi
    securityContext:
      runAsUser: 1012310000  # appuser
      runAsGroup: 1012310000
      runAsNonRoot: true
    # Add writable volumes for Kafka
    additionalVolumes:
      - name: kafka-logs
        emptyDir: {}
      - name: kafka-metadata
        emptyDir: {}
      - name: kafka-config
        emptyDir: {}
    additionalVolumeMounts:
      - name: kafka-logs
        mountPath: /tmp/kafka-logs
      - name: kafka-metadata
        mountPath: /tmp/kafka-metadata
      - name: kafka-config
        mountPath: /tmp/kafka-config
    # Override the start command to copy config to writable location
    command:
      - "/bin/bash"
      - "-c"
      - |
        mkdir -p /tmp/kafka-config /tmp/kafka-logs /tmp/kafka-metadata
        cp -r /opt/kafka/config/* /tmp/kafka-config/
        # Create a custom startup script without GC logging
        cat > /tmp/kafka-start.sh << 'EOF'
        #!/bin/bash
        export KAFKA_HEAP_OPTS="-Xmx400M -Xms400M"
        export KAFKA_JVM_PERFORMANCE_OPTS=""
        export KAFKA_GC_LOG_OPTS=""
        export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/kafka-config/log4j.properties"
        export JAVA_TOOL_OPTIONS=""
        exec java $KAFKA_HEAP_OPTS -cp "/opt/kafka/libs/*" kafka.Kafka /tmp/kafka-config/kraft/server.properties
        EOF
        chmod +x /tmp/kafka-start.sh
        /tmp/kafka-start.sh

  valkey-cart:
    enabled: true
    useDefault:
      env: true
    imageOverride:
      repository: "valkey/valkey"
      tag: "7.2-alpine"
    replicas: 1
    ports:
      - name: valkey-cart
        value: 6379
    resources:
      limits:
        memory: 20Mi
    securityContext:
      runAsUser: 1012310000  # valkey
      runAsGroup: 1012310000
      runAsNonRoot: true
    # Add writable volume for Valkey data and configuration
    additionalVolumes:
      - name: valkey-data
        emptyDir: {}
      - name: valkey-config
        emptyDir: {}
    additionalVolumeMounts:
      - name: valkey-data
        mountPath: /tmp/valkey-data
      - name: valkey-config
        mountPath: /tmp/valkey-config
    # Override command to disable RDB snapshots and use writable directories
    command:
      - "valkey-server"
      - "--save"
      - ""
      - "--appendonly"
      - "no"
      - "--stop-writes-on-bgsave-error"
      - "no"
      - "--dir"
      - "/tmp/valkey-data"
      - "--port"
      - "6379"
      - "--bind"
      - "0.0.0.0"
      - "--protected-mode"
      - "no"

opentelemetry-collector:
  enabled: true
  image:
    repository: "otel/opentelemetry-collector-contrib"
  fullnameOverride: otel-collector
  mode: deployment
  presets:
    kubernetesAttributes:
      enabled: false
  resources:
    limits:
      memory: 200Mi
  service:
    type: ClusterIP
  ports:
    metrics:
      enabled: true
  podAnnotations:
    prometheus.io/scrape: "true"
    opentelemetry_community_demo: "true"
  config:
    receivers:
      otlp:
        protocols:
          http:
            # Since this collector needs to receive data from the web, enable cors for all origins
            # `allowed_origins` can be refined for your deployment domain
            cors:
              allowed_origins:
                - "http://*"
                - "https://*"
      httpcheck/frontend-proxy:
        targets:
          - endpoint: http://frontend-proxy:8080
      redis:
        endpoint: "valkey-cart:6379"
        collection_interval: 10s

    exporters:
      ## Create an exporter to Tempo using the standard `otlp` export format
      otlp:
        endpoint: tempo:4317
        tls:
          insecure: true
      # Create an exporter to Prometheus (metrics)
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        tls:
          insecure: true
      opensearch:
        logs_index: otel
        http:
          endpoint: http://opensearch:9200
          tls:
            insecure: true

    processors:
      # This processor is used to help limit high cardinality on next.js span names
      # When this PR is merged (and released) we can remove this transform processor
      # https://github.com/vercel/next.js/pull/64852
      transform:
        error_mode: ignore
        trace_statements:
          - context: span
            statements:
              # could be removed when https://github.com/vercel/next.js/pull/64852 is fixed upstream
              - replace_pattern(name, "\\?.*", "")
              - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")
      resource:
        attributes:
          - key: service.instance.id
            from_attribute: k8s.pod.uid
            action: insert
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25

    connectors:
      spanmetrics:
        histogram:
          dimensions:
            - name: url.scheme
              default: https
          explicit:
            buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms, 500ms, 1s, 5s, 10s]
        dimensions:
          - name: http.method
            default: GET
          - name: http.status_code
        calls_dimensions:
          - name: http.url
            default: /ping
        exemplars:
          enabled: true
        exclude_dimensions: ['status.code']
        aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"    
        metrics_flush_interval: 15s
        metrics_expiration: 5m
        events:
          enabled: true
          dimensions:
            - name: exception.type
            - name: exception.message
        resource_metrics_key_attributes:
          - service.name
          - telemetry.sdk.language
          - telemetry.sdk.name
        include_instrumentation_scope:
          - express
      servicegraph:
        latency_histogram_buckets: [10ms, 100ms, 250ms, 1s, 5s]
        dimensions:
          - peer_service

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, resource, transform, batch]
          exporters: [otlp, debug, spanmetrics, servicegraph]
        metrics:
          receivers: [httpcheck/frontend-proxy, redis, otlp, spanmetrics, servicegraph]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/prometheus, debug]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, resource, batch]
          exporters: [debug]
      telemetry:
        metrics:
          level: detailed
          readers:
            - periodic:
                interval: 10000
                timeout: 5000
                exporter:
                  otlp:
                    protocol: grpc
                    endpoint: otel-collector:4317

jaeger:
  enabled: false
  fullnameOverride: jaeger
  provisionDataStore:
    cassandra: false
  allInOne:
    enabled: true
    args:
      - "--memory.max-traces=5000"
      - "--query.base-path=/jaeger/ui"
      - "--prometheus.server-url=http://prometheus:9090"
      - "--prometheus.query.normalize-calls=true"
      - "--prometheus.query.normalize-duration=true"
    extraEnv:
      - name: METRICS_STORAGE_TYPE
        value: prometheus
      - name: COLLECTOR_OTLP_GRPC_HOST_PORT
        value: 0.0.0.0:4317
      - name: COLLECTOR_OTLP_HTTP_HOST_PORT
        value: 0.0.0.0:4318
    resources:
      limits:
        memory: 400Mi
  storage:
    type: memory
  agent:
    enabled: false
  collector:
    enabled: false
  query:
    enabled: false

prometheus:
  enabled: true
  extraManifests: 
    - |
      kind: RoleBinding
      apiVersion: rbac.authorization.k8s.io/v1
      metadata:
        name: prometheus-view-rolebinding
      subjects:
        - kind: ServiceAccount
          name: prometheus
          namespace: valaise16-dev
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: view
  rbac:
    create: false
  alertmanager:
    enabled: false
  configmapReload:
    prometheus:
      enabled: false
  kube-state-metrics:
    enabled: false
  prometheus-node-exporter:
    enabled: false
  prometheus-pushgateway:
    enabled: false
  server:
    securityContext:
      runAsUser: 1012310000
      runAsNonRoot: true
      runAsGroup: 1012310000
      fsGroup: 1012310000
    ingress:
      enabled: true
      annotations:
        # Let OpenShift create a secure Route
        route.openshift.io/termination: "edge"
        route.openshift.io/insecureEdgeTerminationPolicy: "Redirect"   
      hosts:
        - prometheus-valaise16-dev.apps.rm3.7wse.p1.openshiftapps.com
      tls: []
    fullnameOverride: prometheus
    extraFlags:
      - "enable-feature=exemplar-storage"
      - "web.enable-otlp-receiver"
    tsdb:
      out_of_order_time_window: 30m
    otlp:
      keep_identifying_resource_attributes: true
      # Recommended attributes to be promoted to labels.
      promote_resource_attributes:
        - service.instance.id
        - service.name
        - service.namespace
        - service.version
        # When deploying on Kubernetes, resource attributes used to identify the
        # kubernetes resources in dashboards and alerts.
        - k8s.container.name
        - k8s.deployment.name
        - k8s.job.name
        - k8s.namespace.name
        - k8s.pod.name
        - k8s.replicaset.name
        - k8s.statefulset.name
        - k8s.node.name
        - k8s.daemonset.name
        - k8s.cluster.name
        - k8s.pod.uid
        - container.name
        # When deploying on VMs, resource attributes used to identify
        # the host in dashboards and alerts.
        - host.name
    persistentVolume:
      enabled: false
    service:
      servicePort: 9090
    resources:
      limits:
        memory: 300Mi

grafana:
  enabled: true
  securityContext:
    runAsNonRoot: true
    runAsUser: 1012310000
    runAsGroup: 1012310000
    fsGroup: 1012310000
  ingress:
    enabled: true
    annotations:
      # Let OpenShift create a secure Route
      route.openshift.io/termination: "edge"
      route.openshift.io/insecureEdgeTerminationPolicy: "Redirect"   

    hosts:
      - grafana-valaise16-dev.apps.rm3.7wse.p1.openshiftapps.com
    paths:
      - path: /
        pathType: Prefix
  rbac:
    create: false
    pspEnabled: false
    clusterRole: false
  fullnameOverride: grafana
  testFramework:
    enabled: false
  grafana.ini:
    auth:
      disable_login_form: true
    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Admin
    server:
      root_url: "%(protocol)s://%(domain)s"
      serve_from_sub_path: true
  adminPassword: admin
  plugins:
    - grafana-opensearch-datasource
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          uid: webstore-metrics
          type: prometheus
          url: http://prometheus:9090
          editable: true
          isDefault: true
          jsonData:
            exemplarTraceIdDestinations:
              - datasourceUid: webstore-traces
                name: trace_id
        - name: Tempo
          uid: webstore-traces
          type: tempo
          access: proxy
          url: http://tempo:3200
          jsonData:
            httpMethod: GET
            # Enable service map using Prometheus as the data source for service graph metrics
            serviceMap:
              datasourceUid: "webstore-metrics"
            # Configure trace to logs correlation
            tracesToLogs:
              datasourceUid: "webstore-logs"
              tags: ["service.name", "service.instance.id", "service.version"]
              mappedTags:
                - key: service.name
                  value: service
                - key: service.instance.id
                  value: instance
                - key: service.version
                  value: version
              mapTagNamesEnabled: true
              spanStartTimeShift: "1h"
              spanEndTimeShift: "1h"
              filterByTraceID: true
              filterBySpanID: false
              customQuery: true
            # Configure trace to metrics correlation
            tracesToMetrics:
              datasourceUid: webstore-metrics
              spanStartTimeShift: "1h"
              spanEndTimeShift: "1h"
              tags:
                - { key: "service.name", value: "service" }
                - { key: "http.method", value: "method" }
                - { key: "http.status_code", value: "status_code" }
              queries:
                - name: "Request rate"
                  query: "sum(rate(traces_spanmetrics_calls_total{$$__tags}[5m])) by (service)"
                  unit: "req/s"
                - name: "Request duration"
                  query: "histogram_quantile(0.95, sum(rate(traces_spanmetrics_duration_bucket{$$__tags}[5m])) by (le, service))"
                  unit: "s"
                - name: "Request failures"
                  query: "sum(rate(traces_spanmetrics_calls_total{$$__tags,status_code!~\"2..\"}[5m])) by (service)"
                  unit: "req/s"
                - name: "Service graph request rate"
                  query: "sum(rate(traces_service_graph_request_total{$$__tags}[5m])) by (client, server)"
                  unit: "req/s"
            # Configure search settings
            search:
              hide: false
            nodeGraph:
              enabled: true
            # Configure span bar
            spanBar:
              type: "Tag"
              tag: "http.path"
          editable: true
        - name: OpenSearch
          uid: webstore-logs
          type: grafana-opensearch-datasource
          url: http://opensearch:9200/
          access: proxy
          editable: true
          isDefault: false
          jsonData:
            database: otel
            flavor: opensearch
            logLevelField: severity.text.keyword
            logMessageField: body
            pplEnabled: true
            timeField: observedTimestamp
            version: 2.18.0
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'sloth-remote-provider'
          orgId: 1
          folder: 'SLOs Dashboards'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/sloth-remote
        - name: 'sloth-cm-provider'
          orgId: 1
          folder: 'Observability dashboards'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/sloth-cm
  dashboardsConfigMaps:
    sloth-cm: grafana-dashboards
  dashboards:
    sloth-remote:
      sloth-slo-detail:
        gnetId: 14348
        revision: 1
        datasource: Prometheus
      sloth-slos-high-level:
        gnetId: 14643
        revision: 1
        datasource: Prometheus
      prometheus-stats:
        gnetId: 15489
        revision: 1
        datasource: Prometheus
  resources:
    limits:
      memory: 150Mi

# Enable embedded Tempo by default for local use; can be disabled via values
tempo:
  enabled: true
  securityContext:
    runAsUser: 1012310000
    runAsNonRoot: true
    runAsGroup: 1012310000
    fsGroup: 1012310000
  fullnameOverride: tempo
  tempo:
    persistence:
      enabled: false
    storage:
      trace:
        backend: local
        local:
          path: /tmp/tempo
        wal:
          path: /tmp/tempo/wal
    # Use writable directory for tempo data
    extraVolumeMounts:
      - name: tempo-data
        mountPath: /tmp/tempo
  extraVolumes:
    - name: tempo-data
      emptyDir: {}

opensearch:
  enabled: false
  fullnameOverride: opensearch
  clusterName: demo-cluster
  nodeGroup: otel-demo
  singleNode: true
  opensearchJavaOpts: "-Xms300m -Xmx300m"
  persistence:
    enabled: false
  extraEnvs:
    - name: "bootstrap.memory_lock"
      value: "true"
    - name: "DISABLE_INSTALL_DEMO_CONFIG"
      value: "true"
    - name: "DISABLE_SECURITY_PLUGIN"
      value: "true"
  resources:
    limits:
      memory: 1100Mi
