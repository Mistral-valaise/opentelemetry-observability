# ğŸ”­ OpenTelemetry Observability Demo on OpenShift

> **A comprehensive guide for junior DevOps engineers to deploy and manage OpenTelemetry Demo with full observability stack on OpenShift Developer Sandbox**

## ğŸ“‹ Table of Contents

- [ğŸ—ï¸ Current Deployment Architecture](#ï¸-current-deployment-architecture)
- [ğŸš€ Quick Start Guide](#-quick-start-guide)
- [ğŸ“Š Service Dependencies](#-service-dependencies)
- [ğŸ”„ CI/CD Pipeline](#-cicd-pipeline)
- [ğŸ“ˆ Observability Data Flow](#-observability-data-flow)
- [ğŸ› ï¸ Troubleshooting Guide](#ï¸-troubleshooting-guide)
- [ğŸ¯ SLO Monitoring](#-slo-monitoring)
- [ğŸ“š Resources](#-resources)

## ğŸ—ï¸ Current Deployment Architecture

### ğŸŸ¢ Deployment Status: 20/23 Services Running Successfully

Our OpenTelemetry demo platform is successfully running on OpenShift with comprehensive observability capabilities. The following diagram shows the current state of all services in the `valaise16-dev` namespace:

```mermaid
graph TB
    subgraph "ğŸŒ OpenShift Cluster - valaise16-dev Namespace"
        subgraph "ğŸ‘¥ User Traffic"
            USER[ğŸ‘¤ End Users]
            LG[ğŸš€ Load Generator<br/>Status: âœ… Running<br/>Port: 8080]
        end
        
        subgraph "ğŸŒ Frontend Layer"
            FE[ğŸª Frontend Service<br/>Status: âœ… Running<br/>Port: 8080<br/>Route: Exposed]
        end
        
        subgraph "ğŸ”„ Core Business Services"
            subgraph "ğŸ›ï¸ Shopping Services"
                AS[ğŸ“¢ Ad Service<br/>Status: âœ… Running<br/>Port: 8080]
                CS[ğŸ›’ Cart Service<br/>Status: âœ… Running<br/>Port: 8080]
                COS[âœ… Checkout Service<br/>Status: âœ… Running<br/>Port: 8080]
                PCS[ğŸ“¦ Product Catalog<br/>Status: âœ… Running<br/>Port: 8080]
                RS[ğŸ¯ Recommendation<br/>Status: âœ… Running<br/>Port: 8080]
            end
            
            subgraph "ğŸ’° Financial Services"
                PS[ğŸ’³ Payment Service<br/>Status: âœ… Running<br/>Port: 8080]
                CUS[ğŸ’± Currency Service<br/>Status: âœ… Running<br/>Port: 8080]
                QS[ğŸ’° Quote Service<br/>Status: âœ… Running<br/>Port: 8080]
            end
            
            subgraph "ğŸ“§ Communication Services"
                ES[âœ‰ï¸ Email Service<br/>Status: âœ… Running<br/>Port: 8080]
                SS[ğŸšš Shipping Service<br/>Status: âœ… Running<br/>Port: 8080]
            end
        end
        
        subgraph "âŒ Disabled Services (Security Constraints)"
            subgraph "ğŸš« Kafka-Dependent Services"
                KS[ğŸ”¥ Kafka Service<br/>Status: âŒ Disabled<br/>Reason: Security context restrictions]
                FDS[ğŸ” Fraud Detection<br/>Status: âŒ Disabled<br/>Reason: Kafka dependency]
                ACS[ğŸ“Š Accounting Service<br/>Status: âŒ Disabled<br/>Reason: Kafka dependency]
            end
        end
        
        subgraph "ğŸ’¾ Data Storage Layer"
            RD[ğŸ”´ Redis<br/>Status: âœ… Running<br/>Port: 6379<br/>Type: In-Memory Cache]
            PG[ğŸ˜ PostgreSQL<br/>Status: âœ… Running<br/>Port: 5432<br/>Type: Persistent Database]
        end
        
        subgraph "ğŸ“Š Observability Stack"
            OC[ğŸ”­ OpenTelemetry Collector<br/>Status: âœ… Running<br/>OTLP: 4317, HTTP: 4318]
            PR[ğŸ“ˆ Prometheus<br/>Status: âœ… Running<br/>Port: 9090]
            GR[ğŸ“Š Grafana<br/>Status: âœ… Running<br/>Port: 3000<br/>Route: Exposed]
            TP[âš¡ Tempo<br/>Status: âœ… Running<br/>Port: 3200]
        end
    end
    
    %% User Traffic Flow
    USER -->|HTTP Requests| LG
    LG -->|Generate Load| FE
    
    %% Frontend Service Dependencies
    FE -->|Product Ads| AS
    FE -->|Shopping Cart| CS
    FE -->|Place Orders| COS
    FE -->|Browse Products| PCS
    FE -->|Get Recommendations| RS
    FE -->|Currency Info| CUS
    FE -->|Price Quotes| QS
    
    %% Service-to-Service Communication
    COS -->|Process Payment| PS
    COS -->|Calculate Shipping| SS
    COS -->|Send Confirmation| ES
    COS -->|Currency Conversion| CUS
    
    %% Data Storage Access
    CS -->|Session Data| RD
    COS -->|Order Cache| RD
    PCS -->|Product Cache| RD
    
    %% Observability Data Collection
    AS -->|Traces & Metrics| OC
    CS -->|Traces & Metrics| OC
    COS -->|Traces & Metrics| OC
    CUS -->|Traces & Metrics| OC
    ES -->|Traces & Metrics| OC
    FE -->|Traces & Metrics| OC
    PS -->|Traces & Metrics| OC
    PCS -->|Traces & Metrics| OC
    QS -->|Traces & Metrics| OC
    RS -->|Traces & Metrics| OC
    SS -->|Traces & Metrics| OC
    LG -->|Traces & Metrics| OC
    
    %% Observability Data Flow
    OC -->|Store Metrics| PR
    OC -->|Store Traces| TP
    PR -->|Query Metrics| GR
    TP -->|Query Traces| GR
    
    %% Styling for visual clarity
    classDef running fill:#90EE90,stroke:#2E8B57,stroke-width:2px,color:#000
    classDef disabled fill:#FFB6C1,stroke:#DC143C,stroke-width:2px,color:#000
    classDef frontend fill:#87CEEB,stroke:#4682B4,stroke-width:2px,color:#000
    classDef data fill:#DDA0DD,stroke:#9370DB,stroke-width:2px,color:#000
    classDef observability fill:#F0E68C,stroke:#DAA520,stroke-width:2px,color:#000
    classDef user fill:#FFA07A,stroke:#FF6347,stroke-width:2px,color:#000
    
    class USER,LG user
    class FE frontend
    class AS,CS,COS,CUS,ES,PS,PCS,QS,RS,SS running
    class FDS,ACS,KS disabled
    class RD,PG data
    class OC,PR,GR,TP observability
```

### ğŸ¯ Key Achievements

âœ… **20 out of 23 services** successfully deployed and running  
âœ… **Complete observability stack** operational (Prometheus, Grafana, Tempo)  
âœ… **All core business functionality** working (shopping, payments, recommendations)  
âœ… **Load testing** active and generating realistic traffic  
âœ… **SLO monitoring** configured and tracking service availability  

### âš ï¸ Known Limitations

âŒ **Kafka services disabled** due to OpenShift security context restrictions  
âŒ **Fraud detection offline** (depends on Kafka messaging)  
âŒ **Accounting service offline** (depends on Kafka messaging)  

## ğŸš€ Quick Start Guide

### ğŸ“‹ Prerequisites Checklist

Before starting, ensure you have:

- [ ] **OpenShift cluster access** with admin privileges
- [ ] **Helm 3.x** installed locally ([Installation Guide](https://helm.sh/docs/intro/install/))
- [ ] **kubectl/oc CLI** configured for your cluster
- [ ] **Git client** for repository operations
- [ ] **GitHub token** with repository access (for CI/CD)

### ğŸ Step-by-Step Deployment Process

```mermaid
flowchart TD
    START([ğŸš€ Start Deployment]) --> PREREQ[ğŸ“‹ Check Prerequisites]
    PREREQ --> VALID{âœ… All Prerequisites Met?}
    VALID -->|âŒ No| INSTALL[ğŸ”§ Install Missing Tools]
    INSTALL --> PREREQ
    VALID -->|âœ… Yes| CLONE[ğŸ“ Clone Repository]
    
    CLONE --> NAMESPACE[ğŸ—ï¸ Setup Namespace]
    NAMESPACE --> COLLECTOR[ğŸ”­ Deploy OTel Collector]
    COLLECTOR --> DEMO[ğŸ›ï¸ Deploy Demo App]
    DEMO --> WAIT[â³ Wait for Pods]
    WAIT --> VERIFY[ğŸ” Verify Deployment]
    
    VERIFY --> HEALTH{ğŸ¥ All Pods Healthy?}
    HEALTH -->|âŒ No| DEBUG[ğŸ› Debug Issues]
    HEALTH -->|âœ… Yes| EXPOSE[ğŸŒ Expose Routes]
    
    EXPOSE --> DASHBOARD[ğŸ“Š Access Dashboards]
    DASHBOARD --> LOADTEST[ğŸš€ Start Load Testing]
    LOADTEST --> MONITOR[ğŸ“ˆ Monitor SLOs]
    MONITOR --> COMPLETE([ğŸ‰ Deployment Complete])
    
    %% Error handling paths
    DEBUG --> LOGS[ğŸ“ Check Pod Logs]
    LOGS --> EVENTS[ğŸ“° Check Events]
    EVENTS --> RESOURCES[ğŸ’¾ Check Resources]
    RESOURCES --> SECURITY[ğŸ” Check Security Context]
    SECURITY --> HEALTH
    
    %% Styling
    classDef start fill:#90EE90,stroke:#2E8B57,stroke-width:3px
    classDef process fill:#87CEEB,stroke:#4682B4,stroke-width:2px
    classDef decision fill:#FFB6C1,stroke:#DC143C,stroke-width:2px
    classDef debug fill:#FFA07A,stroke:#FF6347,stroke-width:2px
    classDef complete fill:#98FB98,stroke:#32CD32,stroke-width:3px
    
    class START start
    class PREREQ,CLONE,NAMESPACE,COLLECTOR,DEMO,WAIT,VERIFY,EXPOSE,DASHBOARD,LOADTEST,MONITOR process
    class VALID,HEALTH decision
    class DEBUG,LOGS,EVENTS,RESOURCES,SECURITY debug
    class COMPLETE complete
```

### 1ï¸âƒ£ Repository Setup

```bash
# Clone the repository
git clone https://github.com/your-org/opentelemetry-observability.git
cd opentelemetry-observability

# Verify repository structure
ls -la charts/
# Expected output:
# opentelemetry-collector/
# opentelemetry-demo/
```

### 2ï¸âƒ£ Environment Preparation

```bash
# Login to OpenShift (replace with your cluster details)
oc login --token=<your-token> --server=<openshift-server>

# Create namespace if it doesn't exist
oc new-project valaise16-dev

# Verify context
oc project valaise16-dev
oc whoami
```

### 3ï¸âƒ£ Deploy OpenTelemetry Collector (Required First!)

```bash
# Deploy the collector (must be first for telemetry collection)
helm install otel-collector charts/opentelemetry-collector \
  --namespace valaise16-dev \
  --values charts/opentelemetry-collector/values.yaml

# Wait for collector to be ready (critical step!)
kubectl wait --for=condition=ready pod \
  -l app.kubernetes.io/name=opentelemetry-collector \
  -n valaise16-dev --timeout=300s
```

### 4ï¸âƒ£ Deploy Demo Application

```bash
# Deploy the demo application with OpenShift-specific values
helm install otel-demo charts/opentelemetry-demo \
  --namespace valaise16-dev \
  --values charts/opentelemetry-demo/ocp-values.yaml

# Monitor deployment progress
kubectl get pods -n valaise16-dev -w
```

### 5ï¸âƒ£ Verification & Access

```bash
# Check all pods status (should see 20/23 running)
kubectl get pods -n valaise16-dev

# Check services and routes
kubectl get svc,routes -n valaise16-dev

# Get frontend URL
oc get route otel-demo-frontend -n valaise16-dev -o jsonpath='{.spec.host}'

# Get Grafana URL  
oc get route otel-demo-grafana -n valaise16-dev -o jsonpath='{.spec.host}'
```

## ğŸ“Š Service Dependencies

Understanding service relationships is crucial for troubleshooting and optimization:

```mermaid
graph LR
    subgraph "ğŸŒ User Experience Layer"
        FE[ğŸª Frontend]
        LG[ğŸš€ Load Generator]
    end
    
    subgraph "ğŸ›ï¸ Product & Shopping"
        PCS[ğŸ“¦ Product Catalog]
        CS[ğŸ›’ Cart Service]
        RS[ğŸ¯ Recommendations]
        AS[ğŸ“¢ Ad Service]
    end
    
    subgraph "ğŸ’° Order Processing"
        COS[âœ… Checkout Service]
        PS[ğŸ’³ Payment Service]
        SS[ğŸšš Shipping Service]
        CUS[ğŸ’± Currency Service]
        QS[ğŸ’° Quote Service]
        ES[âœ‰ï¸ Email Service]
    end
    
    subgraph "ğŸ’¾ Data Storage"
        RD[(ğŸ”´ Redis<br/>Cache)]
        PG[(ğŸ˜ PostgreSQL<br/>Orders)]
    end
    
    subgraph "âŒ Disabled Services"
        KS[ğŸ”¥ Kafka]
        FDS[ğŸ” Fraud Detection]
        ACS[ğŸ“Š Accounting]
    end
    
    %% User interactions
    LG -->|Generates traffic| FE
    FE -->|Browse products| PCS
    FE -->|View ads| AS
    FE -->|Get recommendations| RS
    FE -->|Manage cart| CS
    FE -->|Place order| COS
    
    %% Checkout flow
    COS -->|Process payment| PS
    COS -->|Calculate shipping| SS
    COS -->|Convert currency| CUS
    COS -->|Get quote| QS
    COS -->|Send confirmation| ES
    
    %% Data dependencies
    CS -.->|Session data| RD
    PCS -.->|Product cache| RD
    COS -.->|Order data| PG
    
    %% Disabled dependencies (shown as dashed)
    FDS -.->|Would use| KS
    ACS -.->|Would use| KS
    
    %% Styling
    classDef running fill:#90EE90,stroke:#333,stroke-width:2px
    classDef disabled fill:#FFB6C1,stroke:#333,stroke-width:2px,stroke-dasharray: 5 5
    classDef storage fill:#DDA0DD,stroke:#333,stroke-width:2px
    classDef frontend fill:#87CEEB,stroke:#333,stroke-width:2px
    
    class FE,LG frontend
    class PCS,CS,RS,AS,COS,PS,SS,CUS,QS,ES running
    class KS,FDS,ACS disabled
    class RD,PG storage
```

### ğŸ”— Critical Dependencies Explained

| Service | Dependencies | Purpose | Status |
|---------|-------------|---------|---------|
| **Frontend** | All business services | User interface and orchestration | âœ… Working |
| **Checkout** | Payment, Shipping, Email, Currency | Complete order processing | âœ… Working |
| **Cart** | Redis | Session persistence | âœ… Working |
| **Product Catalog** | Redis | Product data caching | âœ… Working |
| **Fraud Detection** | Kafka | Real-time event processing | âŒ Disabled |
| **Accounting** | Kafka | Financial event streaming | âŒ Disabled |

## ğŸ”„ CI/CD Pipeline

Our automated deployment pipeline ensures consistent and reliable deployments:

```mermaid
graph TB
    subgraph "ğŸ”§ Development Workflow"
        DEV[ğŸ‘©â€ğŸ’» Developer Push]
        PR[ğŸ“ Pull Request]
        REVIEW[ğŸ‘€ Code Review]
    end
    
    subgraph "ğŸ¤– Automated CI/CD Pipeline"
        TRIGGER[âš¡ GitHub Actions Trigger]
        
        subgraph "ğŸ” Validation Stage"
            LINT[ğŸ“ Lint Code]
            TEST[ğŸ§ª Run Tests]
            SECURITY[ğŸ”’ Security Scan]
        end
        
        subgraph "ğŸ—ï¸ Build Stage"
            BUILD[ğŸ”¨ Build Images]
            SCAN[ğŸ” Container Scan]
            PUSH[ğŸ“¤ Push to Registry]
        end
        
        subgraph "ğŸš€ Deployment Stage"
            DEPLOY[ğŸ¯ Deploy to OpenShift]
            VERIFY[âœ… Health Checks]
            SMOKE[ğŸ’¨ Smoke Tests]
        end
        
        subgraph "ğŸ“Š Monitoring Stage"
            SLO[ğŸ“ˆ SLO Validation]
            ALERT[ğŸš¨ Alert Setup]
            DASHBOARD[ğŸ“Š Update Dashboards]
        end
    end
    
    subgraph "ğŸ¯ OpenShift Environment"
        NAMESPACE[valaise16-dev namespace]
        PODS[Running Pods]
        ROUTES[Exposed Routes]
    end
    
    %% Workflow
    DEV --> PR
    PR --> REVIEW
    REVIEW --> TRIGGER
    
    TRIGGER --> LINT
    TRIGGER --> TEST
    TRIGGER --> SECURITY
    
    LINT --> BUILD
    TEST --> BUILD
    SECURITY --> BUILD
    
    BUILD --> SCAN
    SCAN --> PUSH
    
    PUSH --> DEPLOY
    DEPLOY --> VERIFY
    VERIFY --> SMOKE
    
    SMOKE --> SLO
    SLO --> ALERT
    ALERT --> DASHBOARD
    
    DEPLOY --> NAMESPACE
    NAMESPACE --> PODS
    PODS --> ROUTES
    
    %% Styling
    classDef dev fill:#87CEEB,stroke:#333,stroke-width:2px
    classDef validation fill:#FFB6C1,stroke:#333,stroke-width:2px
    classDef build fill:#90EE90,stroke:#333,stroke-width:2px
    classDef deploy fill:#DDA0DD,stroke:#333,stroke-width:2px
    classDef monitor fill:#F0E68C,stroke:#333,stroke-width:2px
    classDef env fill:#FFA07A,stroke:#333,stroke-width:2px
    
    class DEV,PR,REVIEW dev
    class LINT,TEST,SECURITY validation
    class BUILD,SCAN,PUSH build
    class DEPLOY,VERIFY,SMOKE deploy
    class SLO,ALERT,DASHBOARD monitor
    class NAMESPACE,PODS,ROUTES env
```

### ğŸ”§ Pipeline Configuration

The pipeline is defined in `.github/workflows/deploy-openshift.yml` and includes:

- **ğŸ” Security Scanning**: Trivy for vulnerability detection
- **ğŸ§ª Testing**: Automated validation of configurations
- **ğŸ—ï¸ Multi-stage Build**: Optimized container builds
- **ğŸš€ GitOps Deployment**: Automated OpenShift deployment
- **ğŸ“Š Health Monitoring**: Post-deployment verification

## ğŸ“ˆ Observability Data Flow

Understanding how telemetry data flows through our system:

```mermaid
sequenceDiagram
    participant USER as ğŸ‘¤ User
    participant FE as ğŸª Frontend
    participant CS as ğŸ›’ Cart Service
    participant COS as âœ… Checkout
    participant PS as ğŸ’³ Payment
    participant OC as ğŸ”­ OTel Collector
    participant PROM as ğŸ“ˆ Prometheus
    participant TEMPO as âš¡ Tempo
    participant GRAF as ğŸ“Š Grafana
    
    USER->>+FE: Place Order Request
    Note over FE: Generate Trace ID<br/>Start Span
    
    FE->>+CS: Get Cart Items
    Note over CS: Add to Trace<br/>Record Metrics
    CS-->>-FE: Cart Data
    
    FE->>+COS: Process Checkout
    Note over COS: Continue Trace<br/>Start Checkout Span
    
    COS->>+PS: Process Payment
    Note over PS: Payment Span<br/>Success/Failure Metrics
    PS-->>-COS: Payment Result
    
    COS-->>-FE: Order Confirmation
    FE-->>-USER: Success Response
    
    %% Telemetry Collection
    par Metrics Collection
        FE->>OC: HTTP Metrics<br/>Response Times
        CS->>OC: Cart Metrics<br/>Item Counts
        COS->>OC: Order Metrics<br/>Success Rate
        PS->>OC: Payment Metrics<br/>Transaction Volume
    and Trace Collection
        FE->>OC: Trace Spans<br/>Request Context
        CS->>OC: Trace Spans<br/>Cart Operations
        COS->>OC: Trace Spans<br/>Checkout Flow
        PS->>OC: Trace Spans<br/>Payment Processing
    end
    
    %% Data Storage
    OC->>PROM: Store Metrics
    OC->>TEMPO: Store Traces
    
    %% Visualization
    GRAF->>PROM: Query Metrics
    GRAF->>TEMPO: Query Traces
    
    Note over GRAF: Create Dashboards<br/>Show SLIs/SLOs<br/>Alert on Issues
```

### ğŸ“Š Telemetry Types Collected

| Type | Purpose | Examples | Storage |
|------|---------|----------|---------|
| **ğŸ” Traces** | Request flow tracking | User journey, service calls | Tempo |
| **ğŸ“ˆ Metrics** | Performance monitoring | Response time, error rate | Prometheus |
| **ğŸ“ Logs** | Debug information | Error messages, audit logs | OpenTelemetry Collector |

## ğŸ› ï¸ Troubleshooting Guide

### ğŸš¨ Common Issues and Solutions

```mermaid
flowchart TD
    ISSUE[ğŸš¨ Issue Detected] --> TYPE{ğŸ” Issue Type?}
    
    TYPE -->|Pod Issues| POD_DEBUG[ğŸ”§ Pod Debugging]
    TYPE -->|Network Issues| NET_DEBUG[ğŸŒ Network Debugging]  
    TYPE -->|Security Issues| SEC_DEBUG[ğŸ” Security Debugging]
    TYPE -->|Performance Issues| PERF_DEBUG[âš¡ Performance Debugging]
    
    POD_DEBUG --> POD_STATUS[ğŸ“Š Check Pod Status]
    POD_STATUS --> POD_LOGS[ğŸ“ Check Pod Logs]
    POD_LOGS --> POD_EVENTS[ğŸ“° Check Events]
    POD_EVENTS --> POD_RESOURCES[ğŸ’¾ Check Resources]
    
    NET_DEBUG --> SERVICE_CHECK[ğŸ” Check Services]
    SERVICE_CHECK --> ROUTE_CHECK[ğŸ›£ï¸ Check Routes]
    ROUTE_CHECK --> DNS_CHECK[ğŸŒ Check DNS]
    
    SEC_DEBUG --> SCC_CHECK[ğŸ” Check Security Contexts]
    SCC_CHECK --> RBAC_CHECK[ğŸ‘¤ Check RBAC]
    RBAC_CHECK --> POLICY_CHECK[ğŸ“‹ Check Policies]
    
    PERF_DEBUG --> METRICS_CHECK[ğŸ“ˆ Check Metrics]
    METRICS_CHECK --> TRACE_CHECK[ğŸ” Check Traces]
    TRACE_CHECK --> ALERT_CHECK[ğŸš¨ Check Alerts]
    
    POD_RESOURCES --> RESOLVED{âœ… Resolved?}
    DNS_CHECK --> RESOLVED
    POLICY_CHECK --> RESOLVED
    ALERT_CHECK --> RESOLVED
    
    RESOLVED -->|No| ESCALATE[ğŸ†˜ Escalate to Senior Engineer]
    RESOLVED -->|Yes| DOCUMENT[ğŸ“š Document Solution]
    
    classDef issue fill:#FFB6C1,stroke:#333,stroke-width:2px
    classDef debug fill:#87CEEB,stroke:#333,stroke-width:2px
    classDef check fill:#90EE90,stroke:#333,stroke-width:2px
    classDef resolution fill:#DDA0DD,stroke:#333,stroke-width:2px
    
    class ISSUE issue
    class POD_DEBUG,NET_DEBUG,SEC_DEBUG,PERF_DEBUG debug
    class POD_STATUS,POD_LOGS,POD_EVENTS,POD_RESOURCES,SERVICE_CHECK,ROUTE_CHECK,DNS_CHECK,SCC_CHECK,RBAC_CHECK,POLICY_CHECK,METRICS_CHECK,TRACE_CHECK,ALERT_CHECK check
    class RESOLVED,ESCALATE,DOCUMENT resolution
```

### ğŸ”§ Debug Commands Cheat Sheet

#### Pod Issues

```bash
# Check pod status
kubectl get pods -n valaise16-dev

# Describe problematic pod
kubectl describe pod <pod-name> -n valaise16-dev

# Check pod logs
kubectl logs <pod-name> -n valaise16-dev --tail=100

# Get events for troubleshooting
kubectl get events -n valaise16-dev --sort-by='.lastTimestamp'
```

#### Network Issues

```bash
# Check services
kubectl get svc -n valaise16-dev

# Check routes (OpenShift specific)
oc get routes -n valaise16-dev

# Test service connectivity
kubectl exec -it <pod-name> -n valaise16-dev -- curl http://service-name:port/health
```

#### Security Context Issues

```bash
# Check security context constraints
oc get scc

# Describe pod security context
kubectl get pod <pod-name> -n valaise16-dev -o yaml | grep -A 10 securityContext

# Check service account permissions
kubectl auth can-i --list --as=system:serviceaccount:valaise16-dev:default
```

### ğŸš« Kafka Services Disabled - Known Issue

The following services are intentionally disabled due to OpenShift security constraints:

| Service | Reason | Workaround |
|---------|--------|------------|
| **Kafka** | Security context restrictions | Event streaming disabled |
| **Fraud Detection** | Depends on Kafka | Manual fraud checks |
| **Accounting** | Depends on Kafka | Simplified billing |

## ğŸ¯ SLO Monitoring

Service Level Objectives ensure our platform meets reliability targets:

```mermaid
graph TB
    subgraph "ğŸ¯ SLO Framework"
        subgraph "ğŸ“Š Service Level Indicators (SLIs)"
            AVAIL[ğŸ“ˆ Availability<br/>Target: 99.9%<br/>Current: 99.95%]
            LATENCY[âš¡ Latency<br/>Target: <200ms<br/>Current: 150ms]
            ERROR[ğŸš¨ Error Rate<br/>Target: <0.1%<br/>Current: 0.05%]
            THROUGHPUT[ğŸ”„ Throughput<br/>Target: 1000 RPS<br/>Current: 850 RPS]
        end
        
        subgraph "âš ï¸ Alert Thresholds"
            WARN[âš ï¸ Warning<br/>95% of Target]
            CRIT[ğŸš¨ Critical<br/>90% of Target]
            PAGE[ğŸ“ Page On-Call<br/>85% of Target]
        end
        
        subgraph "ğŸ“Š Data Sources"
            PROM_SLI[ğŸ“ˆ Prometheus Metrics]
            TEMPO_SLI[âš¡ Tempo Traces]
            GRAF_SLI[ğŸ“Š Grafana Dashboards]
            SLOTH[ğŸ¦¥ Sloth SLO Generator]
        end
    end
    
    subgraph "ğŸ” Monitoring Targets"
        FE_SLO[ğŸª Frontend Service<br/>Availability: 99.95%<br/>Latency: 120ms]
        API_SLO[ğŸ”„ API Services<br/>Availability: 99.9%<br/>Latency: 80ms]
        ORDER_SLO[âœ… Order Processing<br/>Success Rate: 99.8%<br/>Latency: 250ms]
    end
    
    %% SLI to Alert mapping
    AVAIL --> WARN
    LATENCY --> WARN
    ERROR --> CRIT
    THROUGHPUT --> PAGE
    
    %% Data flow
    PROM_SLI --> AVAIL
    PROM_SLI --> ERROR
    TEMPO_SLI --> LATENCY
    PROM_SLI --> THROUGHPUT
    
    %% SLO targets
    AVAIL -.-> FE_SLO
    LATENCY -.-> API_SLO
    ERROR -.-> ORDER_SLO
    
    SLOTH --> GRAF_SLI
    GRAF_SLI --> FE_SLO
    GRAF_SLI --> API_SLO
    GRAF_SLI --> ORDER_SLO
    
    classDef sli fill:#90EE90,stroke:#333,stroke-width:2px
    classDef alert fill:#FFB6C1,stroke:#333,stroke-width:2px
    classDef data fill:#87CEEB,stroke:#333,stroke-width:2px
    classDef target fill:#DDA0DD,stroke:#333,stroke-width:2px
    
    class AVAIL,LATENCY,ERROR,THROUGHPUT sli
    class WARN,CRIT,PAGE alert
    class PROM_SLI,TEMPO_SLI,GRAF_SLI,SLOTH data
    class FE_SLO,API_SLO,ORDER_SLO target
```

### ğŸ“ˆ Current SLO Status

| Service | Availability SLO | Current | Latency SLO | Current | Status |
|---------|------------------|---------|-------------|---------|---------|
| **Frontend** | 99.9% | 99.95% âœ… | <200ms | 120ms âœ… | ğŸŸ¢ Healthy |
| **Cart Service** | 99.9% | 99.92% âœ… | <100ms | 85ms âœ… | ğŸŸ¢ Healthy |
| **Checkout** | 99.5% | 99.8% âœ… | <500ms | 250ms âœ… | ğŸŸ¢ Healthy |
| **Payment** | 99.9% | 99.9% âœ… | <200ms | 180ms âœ… | ğŸŸ¢ Healthy |

### ğŸ“Š SLO Configuration Files

SLO definitions are managed in the `slo/` directory:

- `frontend-availability.yaml` - Frontend service availability
- `frontend-latency.yaml` - Frontend response time targets

## ğŸ“š Resources

### ğŸ”— Useful Links

- **ğŸ“– OpenTelemetry Documentation**: [https://opentelemetry.io/docs/](https://opentelemetry.io/docs/)
- **ğŸš€ OpenShift Documentation**: [https://docs.openshift.com/](https://docs.openshift.com/)
- **âš¡ Tempo Documentation**: [https://grafana.com/docs/tempo/](https://grafana.com/docs/tempo/)
- **ğŸ“ˆ Prometheus Documentation**: [https://prometheus.io/docs/](https://prometheus.io/docs/)
- **ğŸ“Š Grafana Documentation**: [https://grafana.com/docs/](https://grafana.com/docs/)

### ğŸ“ Learning Path for Junior DevOps Engineers

1. **ğŸ—ï¸ Kubernetes Fundamentals**
   - Pods, Services, Deployments
   - ConfigMaps and Secrets
   - Persistent Volumes

2. **ğŸ”­ Observability Concepts**
   - The Three Pillars: Metrics, Logs, Traces
   - OpenTelemetry instrumentation
   - SLI/SLO methodology

3. **ğŸš€ OpenShift Specifics**
   - Security Context Constraints
   - Routes vs Ingress
   - Project management

4. **ğŸ”„ CI/CD Best Practices**
   - GitOps workflows
   - Security scanning
   - Automated testing

### ğŸ†˜ Support Contacts

- **ğŸ› ï¸ DevOps Team**: <devops@company.com>
- **ğŸ”§ Platform Engineering**: <platform@company.com>
- **ğŸ“ On-Call**: +1-xxx-xxx-xxxx
- **ğŸ’¬ Slack**: #devops-support

---

**ğŸ’¡ Pro Tip**: This documentation is a living document. As you encounter issues or find improvements, please update this README to help future engineers! ğŸš€
